{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ActiveTesting.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMn3Nbq2xSYTDh66EjXuq3h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahil3Vedi/Enron-Email-Classifier/blob/master/ActiveTesting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76MMQ42oLQCg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "4351b2bd-1e0a-413c-cbd2-a2cb1958791d"
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0-alpha0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.0.0-alpha0 in /usr/local/lib/python3.6/dist-packages (2.0.0a0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.27.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.17.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.1.8)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.0.dev2019030115)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.9.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.8.1)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190302,>=1.14.0a20190301 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.0a20190301)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (3.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha0) (45.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7vvqUUHZKUx",
        "colab_type": "code",
        "outputId": "3ccb7e93-2f2f-44a1-aba6-d14bdfb334d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUaocuaQZatZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "13f24b0e-dcd0-46cc-98d1-db66fa7f3abf"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.svm import LinearSVC\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Lxdby1PDEww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(x, y):\n",
        "  x = tf.cast(x, tf.float32) / 255.0\n",
        "  y = tf.cast(y, tf.int64)\n",
        "\n",
        "  return x, y\n",
        "\n",
        "def create_dataset(xs, ys, n_classes=10):\n",
        "  ys = tf.one_hot(ys, depth=n_classes)\n",
        "  return tf.data.Dataset.from_tensor_slices((xs, ys)) \\\n",
        "    .map(preprocess) \\\n",
        "    .shuffle(len(ys)) \\\n",
        "    .batch(500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuD3XExaZpx9",
        "colab_type": "code",
        "outputId": "29156ec0-2cd1-4b2b-df14-662131a15650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "#TRAINING\n",
        "ENRONFOLDER = 'drive/My Drive/Enron Spam/'\n",
        "ANNO_LOC = 'drive/My Drive/Enron Spam/annotations.npy'\n",
        "ANNOIND_LOC = 'drive/My Drive/Enron Spam/annotation_indices.npy'\n",
        "FEATURES_LOC = 'drive/My Drive/Enron Spam/featureVectors.npy'\n",
        "ENRONNOSPAMDATASET = 'drive/My Drive/Enron Spam/ham'\n",
        "\n",
        "features = np.load(FEATURES_LOC)\n",
        "ANNO = np.load(ANNOIND_LOC)\n",
        "X_train = []\n",
        "for each_index in ANNO:\n",
        "  X_train.append(features[each_index])\n",
        "Y_load = np.load(ANNO_LOC)\n",
        "\n",
        "Y_train = [each for each in Y_load]\n",
        "\n",
        "model1 = LinearSVC()\n",
        "model1.fit(X_train, Y_train)\n",
        "\n",
        "\n",
        "y_binary = to_categorical(Y_train)\n",
        "\n",
        "XT = np.asarray(X_train)\n",
        "print(np.shape(XT))\n",
        "print(np.shape(y_binary))\n",
        "\n",
        "\n",
        "model2 = tf.keras.Sequential([\n",
        "# Adds a densely-connected layer with 64 units to the model:\n",
        "layers.Dense(64, activation='relu', input_shape=(1000,)),\n",
        "# Add another:\n",
        "layers.Dense(64, activation='relu'),\n",
        "# Add an output layer with 10 output units:\n",
        "layers.Dense(2, activation='softmax')])\n",
        "\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model2.fit(XT, y_binary, epochs=10, batch_size=32)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 1000)\n",
            "(50, 2)\n",
            "Epoch 1/10\n",
            "50/50 [==============================] - 0s 7ms/sample - loss: 0.6990 - accuracy: 0.4000\n",
            "Epoch 2/10\n",
            "50/50 [==============================] - 0s 180us/sample - loss: 0.5568 - accuracy: 0.8000\n",
            "Epoch 3/10\n",
            "50/50 [==============================] - 0s 276us/sample - loss: 0.4571 - accuracy: 0.9400\n",
            "Epoch 4/10\n",
            "50/50 [==============================] - 0s 240us/sample - loss: 0.3829 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "50/50 [==============================] - 0s 227us/sample - loss: 0.3395 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "50/50 [==============================] - 0s 206us/sample - loss: 0.3206 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "50/50 [==============================] - 0s 185us/sample - loss: 0.3158 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "50/50 [==============================] - 0s 189us/sample - loss: 0.3140 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "50/50 [==============================] - 0s 208us/sample - loss: 0.3135 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "50/50 [==============================] - 0s 187us/sample - loss: 0.3133 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5c60386358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZcHSk_LbJVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TESTING\n",
        "def fetchLabel(mailIndex):\n",
        "  twoD_array = []\n",
        "  feature_vector = features[mailIndex]\n",
        "  twoD_array.append(feature_vector)\n",
        "  file_location = os.listdir(ENRONNOSPAMDATASET)[mailIndex]\n",
        "  FILENAME = os.path.join(ENRONNOSPAMDATASET, file_location)\n",
        "  with open(FILENAME, 'r',encoding='utf-8',errors='ignore') as myfile:\n",
        "    data = myfile.read()\n",
        "    #print(\"Message Contents: \")\n",
        "    #print(data)\n",
        "    #print(\"Classifier Label: \")\n",
        "    result1 = model1.predict(twoD_array)[0]\n",
        "    DD = np.asarray(twoD_array)\n",
        "    #print(np.shape(DD))\n",
        "    result2 = model2.predict(DD)\n",
        "    fetch_results = [result1,result2]\n",
        "    return fetch_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVALjpKOc0RS",
        "colab_type": "code",
        "outputId": "3ec9169e-89a6-40e5-924b-621394d7271c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "results1 = []\n",
        "results2 = []\n",
        "for x in range(10):\n",
        "  labels = fetchLabel(x)\n",
        "  results1.append(labels[0])\n",
        "  results2.append(labels[1])\n",
        "print(results1)\n",
        "print(results2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "[array([[1.000000e+00, 2.984492e-15]], dtype=float32), array([[9.9998498e-01, 1.4963661e-05]], dtype=float32), array([[1.0000000e+00, 1.8749707e-12]], dtype=float32), array([[0.8725409 , 0.12745917]], dtype=float32), array([[0.99870014, 0.00129979]], dtype=float32), array([[4.239726e-10, 1.000000e+00]], dtype=float32), array([[0.7820189 , 0.21798109]], dtype=float32), array([[9.999999e-01, 9.409231e-08]], dtype=float32), array([[9.9997187e-01, 2.8140907e-05]], dtype=float32), array([[9.9999952e-01, 5.3027327e-07]], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}