{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Response Generation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMV8u5daq1xKCjLBhXeQZpJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahil3Vedi/Enron-Email-Classifier/blob/master/Response_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxxTIO9xSgYU",
        "colab_type": "code",
        "outputId": "1cb09d8a-7a7e-44d4-e453-f32dcfbe5061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv12fTp6jJDq",
        "colab_type": "code",
        "outputId": "ddcf9f50-1ffb-4b7e-cb25-1644262df4ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.svm import LinearSVC\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdquaL1SjJky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(x, y):\n",
        "  x = tf.cast(x, tf.float32) / 255.0\n",
        "  y = tf.cast(y, tf.int64)\n",
        "\n",
        "  return x, y\n",
        "\n",
        "def create_dataset(xs, ys, n_classes=10):\n",
        "  ys = tf.one_hot(ys, depth=n_classes)\n",
        "  return tf.data.Dataset.from_tensor_slices((xs, ys)) \\\n",
        "    .map(preprocess) \\\n",
        "    .shuffle(len(ys)) \\\n",
        "    .batch(500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYi30YfXnJ7j",
        "colab_type": "code",
        "outputId": "82c995c7-9268-4b0c-9593-bae669261aa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#TRAINING\n",
        "\n",
        "ENRONFOLDER = 'drive/My Drive/Enron Spam/'\n",
        "ENRONNOSPAMDATASET = 'drive/My Drive/Enron Spam/ham'\n",
        "\n",
        "ANNO_LOC = 'drive/My Drive/Enron Spam/annotations.npy'\n",
        "ANNOIND_LOC = 'drive/My Drive/Enron Spam/annotation_indices.npy'\n",
        "CONTEXT_LOC = 'drive/My Drive/Enron Spam/context_annotations.npy'\n",
        "CONTEXTIND_LOC = 'drive/My Drive/Enron Spam/context_annotation_indices.npy'\n",
        "FEATURES_LOC = 'drive/My Drive/Enron Spam/featureVectors.npy'\n",
        "\n",
        "print(\"All vectors loaded!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All vectors loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euiLjhyFotC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_vectors = np.load(FEATURES_LOC)\n",
        "formal_informal_annotations = np.load(ANNO_LOC)\n",
        "formal_informal_indices = np.load(ANNOIND_LOC)\n",
        "context_annotations = np.load(CONTEXT_LOC)\n",
        "context_annotations_indices = np.load(CONTEXTIND_LOC)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc2Jrj0Jpsp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "formal_informal_X = []\n",
        "for each_index in formal_informal_indices:\n",
        "  formal_informal_X.append(feature_vectors[each_index])\n",
        "X_TRAIN_1 = np.asarray(formal_informal_X)\n",
        "Y_LOAD = [each_element for each_element in formal_informal_annotations]\n",
        "Y_TRAIN_1 = to_categorical(Y_LOAD)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhMjJTthwjXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context_X = []\n",
        "for each_index in context_annotations_indices:\n",
        "  context_X.append(feature_vectors[each_index])\n",
        "X_TRAIN_2 = np.asarray(context_X)\n",
        "Y_TRAIN_2 = to_categorical(context_annotations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqCbqi9xx3CA",
        "colab_type": "code",
        "outputId": "a83883f0-ab7c-42a6-896c-1305657794b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(np.shape(X_TRAIN_1))\n",
        "print(np.shape(Y_TRAIN_1))\n",
        "print(np.shape(X_TRAIN_2))\n",
        "print(np.shape(Y_TRAIN_2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 1000)\n",
            "(50, 2)\n",
            "(50, 1000)\n",
            "(50, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F72SX4i004pV",
        "colab_type": "code",
        "outputId": "1d412ba5-8425-478b-9028-88f6ed725440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "#MODEL 1: Formal-Informal_Classifier\n",
        "\n",
        "model1 = tf.keras.Sequential([\n",
        "# Adds a densely-connected layer with 64 units to the model:\n",
        "layers.Dense(64, activation='relu', input_shape=(1000,)),\n",
        "# Add another:\n",
        "layers.Dense(64, activation='relu'),\n",
        "# Add an output layer with 2 output units:\n",
        "layers.Dense(2, activation='softmax')])\n",
        "\n",
        "model1.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model1.fit(X_TRAIN_1, Y_TRAIN_1, epochs=10, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7047 - accuracy: 0.4800\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5877 - accuracy: 0.7200\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.9000\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.9800\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3139 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2ebc2b9278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrSv-H0O2njs",
        "colab_type": "code",
        "outputId": "d1241ec3-d365-4c95-b372-e95a22785f8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "#MODEL 2: Context_Classifier\n",
        "\n",
        "model2 = tf.keras.Sequential([\n",
        "# Adds a densely-connected layer with 64 units to the model:\n",
        "layers.Dense(64, activation='relu', input_shape=(1000,)),\n",
        "# Add another:\n",
        "layers.Dense(100, activation='relu'),\n",
        "# Add an output layer with 4 output units:\n",
        "layers.Dense(4, activation='softmax')])\n",
        "\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model2.fit(X_TRAIN_2, Y_TRAIN_2, epochs=10, batch_size=25)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.3633 - accuracy: 0.3800\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.1440 - accuracy: 0.5400\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.9582 - accuracy: 0.8200\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.8716 - accuracy: 0.9200\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.8173 - accuracy: 0.9600\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.7893 - accuracy: 0.9800\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7780 - accuracy: 0.9600\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.7499 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.7463 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.7489 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2eb8fde9b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlLVCPE_48EL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generating Responses for random mails:\n",
        "\n",
        "def fetchLabel(mailIndex):\n",
        "  twoD_array = []\n",
        "  classification1 = \"\"\n",
        "  classification2 = \"\"\n",
        "  responseHeader = \"\"\n",
        "  responseFooter = \"\"\n",
        "  R1 = []\n",
        "  R2 = []\n",
        "  feature_vector = feature_vectors[mailIndex]\n",
        "  twoD_array.append(feature_vector)\n",
        "  file_location = os.listdir(ENRONNOSPAMDATASET)[mailIndex]\n",
        "  FILENAME = os.path.join(ENRONNOSPAMDATASET, file_location)\n",
        "  DD = np.asarray(twoD_array)\n",
        "  with open(FILENAME, 'r',encoding='utf-8',errors='ignore') as myfile:\n",
        "    data = myfile.read()\n",
        "    print(\"Message Contents: \")\n",
        "    print(data)\n",
        "\n",
        "    result1 = model1.predict(DD)\n",
        "    R1 = [x for x in result1[0]]\n",
        "    maxInd1 = R1.index(max(R1))\n",
        "    if(maxInd1==0):\n",
        "      classification1=\"formal\"\n",
        "      responseFooter = \"Yours Sincerely..\"\n",
        "    elif(maxInd1==1):\n",
        "      classification1=\"informal\"\n",
        "      responseFooter = \"Regards..\"\n",
        "    else:\n",
        "      print(\"Error in Formal-Informal Classification\")\n",
        "    \n",
        "    result2 = model2.predict(DD)\n",
        "    R2 = [y for y in result2[0]]\n",
        "    maxInd2 = R2.index(max(R2))\n",
        "    if(maxInd2==0):\n",
        "      classification2=\"affirmative\"\n",
        "      responseHeader = \"(a) Thank You, I will look into it (b) Thank you for informing\"\n",
        "    elif(maxInd2==1):\n",
        "      classification2=\"proposal\"\n",
        "      responseHeader = \"(a) Sure, we can proceed (b) I am not sure we can proceed\"\n",
        "    elif(maxInd2==2):\n",
        "      classification2=\"followup\"\n",
        "      responseHeader=\"(a) Okay, I will follow up as required (b) Unfortunately, I am unable to follow up\"\n",
        "    elif(maxInd2==3):\n",
        "      classification2=\"invite\"\n",
        "      responseHeader=\"(a) Thank You, I will be there (b) Thank you, but I won't be able to make it\"\n",
        "    else:\n",
        "      print(\"Error in context classification\")\n",
        "\n",
        "    fetch_results = [classification1,classification2]\n",
        "\n",
        "    #generating response based on category:\n",
        "\n",
        "    print(\"\\nResponse:\")\n",
        "    print(responseHeader)\n",
        "    print(responseFooter)\n",
        "\n",
        "    return fetch_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6Qv4Uth7BfB",
        "colab_type": "code",
        "outputId": "b3fd16a5-986e-4eab-d2fa-f816a918e3e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "genIndex = random.randrange(3000)\n",
        "fetchLabel(genIndex)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Message Contents: \n",
            "Subject: re : meter 984229 - roos common point - trade zone 18\n",
            "mary ,\n",
            "hplc currently has a gas purchase agreement ( global # 96014987 ) in place with\n",
            "calpine that extends through 5 / 31 / 2001 . sitara deal no . 133259 correctly has\n",
            "this contract attached to it . effective 11 / 1 / 1998 the contract was amended\n",
            "releasing gouger wells no . 5 & 6 . these wells were apparently the only\n",
            "producing wells behind this point . evidence being no measured volumes in\n",
            "mips . there are however other non producing wells behind this point . is\n",
            "your sept\n",
            "however , they were not added behind meter 6835 . therefore , i do not agree\n",
            "that the deal ( 133259 ) should be edited to change the meter .\n",
            "hopefully this information is useful !\n",
            "vlt\n",
            "x 3 - 6353\n",
            "mary poorman @ enron\n",
            "10 / 23 / 2000 02 : 06 pm\n",
            "to : katherine benedict / hou / ect @ ect , julie meyers / hou / ect @ ect , vance l\n",
            "taylor / hou / ect @ ect , daren j farmer / hou / ect @ ect , pat clynes / corp / enron @ enron\n",
            "cc :\n",
            "subject : meter 984229 - roos common point - trade zone 18\n",
            "i am not sure who should handle this , so , i shared the \" wealth \" . on deal\n",
            "ticket 133259 , purchase from calpine , the deal is input at meter 4229 , which ,\n",
            "per the email below , was terminated . i have an unresolvable ua 4 issue at\n",
            "meter 4229 for september and for october . i have changed the meter\n",
            "designation for november forward , however , i receive an error in sitara when\n",
            "i attempt to change either the prior or current month . this deal should have\n",
            "been changed to meter 6835 effective back in february of this year . please\n",
            "let me know what i can do to resolve this issue asap .\n",
            "thanks ,\n",
            "mary\n",
            "- - - - - - - - - - - - - - - - - - - - - - forwarded by mary poorman / na / enron on 10 / 23 / 2000 02 : 01\n",
            "pm - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "from : cheryl jones 10 / 03 / 2000 08 : 55 am\n",
            "to : katherine benedict / hou / ect @ ect , mary poorman / na / enron @ enron\n",
            "cc :\n",
            "subject : meter 984229 - roos common point - trade zone 18\n",
            "i just talked to the tech - bobby husky and he confirmed that meter 984229 has\n",
            "been removed . now the other roos station is 986835 .\n",
            "thanks ,\n",
            "c . j . x 67787\n",
            "- - - - - - - - - - - - - - - - - - - - - - forwarded by cheryl jones / gpgfin / enron on 10 / 03 / 2000\n",
            "08 : 51 am - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "katherine benedict @ ect\n",
            "09 / 20 / 2000 10 : 01 am\n",
            "to : cheryl jones / gpgfin / enron @ enron , mary poorman / na / enron @ enron\n",
            "cc :\n",
            "subject : meter 984229 - roos common point - trade zone 18\n",
            "cheryl ,\n",
            "fyi - here is the message from mary poorman in logistics .\n",
            "mary ,\n",
            "cheryl is going to call the field and find out if this meter should still be\n",
            "included on the termination list and also see if the field people see any gas\n",
            "flow on the meter .\n",
            "thanks ,\n",
            "kathy\n",
            "- - - - - - - - - - - - - - - - - - - - - - forwarded by katherine benedict / hou / ect on 09 / 20 / 2000\n",
            "09 : 56 am - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "mary poorman @ enron\n",
            "09 / 20 / 2000 09 : 48 am\n",
            "to : robert cotten / hou / ect @ ect , vance l taylor / hou / ect @ ect\n",
            "cc : katherine benedict / enron _ development @ enron _ development\n",
            "subject : meter 984229 - roos common point - trade zone 18\n",
            "kathy and i are trying to clean up an unaccounted for issue at the above\n",
            "referenced meter . the system ( pops ) does not show a bav flow or an actual\n",
            "flow for prior months . kathy phoned measurement to inquire about mips\n",
            "volumes and was informed that this meter is on a disabled status list back to\n",
            "february , 2000 . i am showing a purchase from calpine at this meter ( deal\n",
            "ticket 133259 ) on gathering agreement\n",
            "i would greatly appreciate your help in determining the current status of\n",
            "this meter and this deal . please forward any information you may have .\n",
            "thank you for your time and patience ,\n",
            "mary\n",
            "\n",
            "Response:\n",
            "(a) Thank You, I will be there (b) Thank you, but I won't be able to make it\n",
            "Yours Sincerely..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['formal', 'invite']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    }
  ]
}